{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MODIS Vegetation Indices Time Series Extraction from Google Earth Engine\n",
    "\n",
    "An all-in-one script to extract time series of the Normalized Difference Vegetation Index (NDVI) and Enhanced Vegetation Index (EVI) from MODIS product on Google Earth Engine."
   ],
   "id": "35f91b17e911f0bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import sys"
   ],
   "id": "e579f9fe20d1a102"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Supportive Tools",
   "id": "c908e6b127aa8c4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modis_scaling(image):\n",
    "    \"\"\"\n",
    "    Apply scales on band values of MODIS image.\n",
    "    :param image: ee.Image\n",
    "    :return: ee.Image\n",
    "    \"\"\"\n",
    "    bands_to_modify = ['NDVI', 'EVI']\n",
    "    scale = ee.Number(0.0001)\n",
    "    \n",
    "    def scale_band(band_name):\n",
    "        band = image.select(band_name)\n",
    "        return band.multiply(scale).rename(band_name)\n",
    "    \n",
    "    # scale values for each band\n",
    "    scaled_bands = [scale_band(band_name) for band_name in bands_to_modify]\n",
    "    scaled_image = ee.ImageCollection(scaled_bands).toBands()\n",
    "    original_names = ee.List(bands_to_modify)\n",
    "    renamed_scaled_image = scaled_image.rename(original_names)\n",
    "    \n",
    "    # combine scaled bands with the original bands\n",
    "    modified_image = image.select(image.bandNames().removeAll(bands_to_modify)).addBands(renamed_scaled_image)\n",
    "    \n",
    "    return modified_image\n",
    "\n",
    "def modis_nir_scaling(image):\n",
    "    \"\"\"\n",
    "    Apply scales on band values of MODIS NIR product (MOD09GQ).\n",
    "    :param image: image: ee.Image\n",
    "    :return: ee.Image\n",
    "    \"\"\"\n",
    "    band_to_select = 'sur_refl_b02' # wavelength 841-876 nm\n",
    "    return image.select(band_to_select).multiply(ee.Number(0.0001)).rename(band_to_select)    \n",
    "\n",
    "def mask_clouds_mod13(image):\n",
    "    qa = image.select('SummaryQA')\n",
    "    mask = qa.bitwiseAnd(0x01).eq(0)    # keep only clear pixels\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def mask_clouds_mod09(image):\n",
    "    qa = image.select('QA')\n",
    "    mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 3).eq(0))\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def get_time_series(roi, image_collection, date_start, date_end, target='NDVI', nir_collection=None):\n",
    "    \"\"\"\n",
    "    Extract band values of vegetation indices and create time series of mean pixel-based indices over the given feature,\n",
    "    using the longitude and latitude of the feature centroid to mark the location.\n",
    "    :param roi: ee.Feature, the region of interest.\n",
    "    :param image_collection: ee.ImageCollection, the image collection to map over. \n",
    "    :param nir_collection: ee.ImageCollection, the image collection to map over.\n",
    "    :param date_start: string, the start date to search image, in format 'YYYY-MM-dd'. \n",
    "    :param date_end: string, the end date to search image, in format 'YYYY-MM-dd'. \n",
    "    :param target: string, 'NDVI' and/or 'EVI' and/or 'NIRv', default to 'NDVI'. \n",
    "    :return: ee.FeatureCollection, containing centroid location and VI values in each feature.\n",
    "    \"\"\"\n",
    "    # get centroid location of the given feature\n",
    "    centroid = roi.geometry().centroid()\n",
    "    lon = centroid.coordinates().get(0)\n",
    "    lat = centroid.coordinates().get(1)\n",
    "    \n",
    "    # filter images by date and location, and apply pre-process on images\n",
    "    ic_to_map = image_collection \\\n",
    "        .filterBounds(roi.geometry()) \\\n",
    "        .filterDate(date_start, date_end) \\\n",
    "        .map(mask_clouds_mod13) \\\n",
    "        .map(modis_scaling)\n",
    "        \n",
    "    # function to aggregate VI for roi\n",
    "    def calc_mean_vi(image):\n",
    "        mean_vi = image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=roi.geometry(),\n",
    "            scale=250,\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "        return ee.Feature(None, {\n",
    "            'system:index': image.get('system:index'),\n",
    "            'lon': lon,\n",
    "            'lat': lat,\n",
    "            'target': mean_vi.get(target)\n",
    "        })\n",
    "    \n",
    "    # function to calculate VI over all images\n",
    "    def get_values_from_image_collection(collection):\n",
    "        vi_features = collection.map(calc_mean_vi)\n",
    "        # filter out null values\n",
    "        vi_filtered = vi_features.filter(ee.Filter.notNull(['target']))\n",
    "        return ee.FeatureCollection(vi_filtered)\n",
    "    \n",
    "    # perform calculation\n",
    "    if target == 'NIRv':\n",
    "        if nir_collection is not None:\n",
    "            image_count = ic_to_map.select('NDVI').size()            \n",
    "            ic_nir_to_map = nir_collection \\\n",
    "                .filterBounds(roi.geometry()) \\\n",
    "                .filterDate(date_start, date_end) \\\n",
    "                .map(mask_clouds_mod09) \\\n",
    "                .map(modis_nir_scaling)\n",
    "                        \n",
    "            # function to aggregate MOD09GQ to 16-day periods (mean)\n",
    "            def aggregate_mod09(date_in):\n",
    "                date_in = ee.Date(date_in)\n",
    "                itv_end = date_in.advance(16, 'day').advance(-1, 'second')\n",
    "                filtered = ic_nir_to_map.filterDate(date_in, itv_end)\n",
    "                \n",
    "                # check if there are images in the filtered collection\n",
    "                nir_count = filtered.size()\n",
    "                aggregated = ee.Image(ee.Algorithms.If(nir_count, filtered.mean(), ee.Image().set('empty', True)))\n",
    "                \n",
    "                return aggregated.set('system:time_start', date_in.millis())\n",
    "            \n",
    "            # create 16-day intervals and filter out empty images\n",
    "            mod13_dates = ic_to_map.aggregate_array('system:time_start').distinct().sort()\n",
    "            agg_mod09 = ee.ImageCollection(mod13_dates.map(aggregate_mod09)) \\\n",
    "                .filter(ee.Filter.notEquals(leftField='empty', rightValue=True))\n",
    "            \n",
    "            # join MOD13Q1 and the aggregated MOD09GQ\n",
    "            join = ee.Join.inner()\n",
    "            filter_time_eq = ee.Filter.equals(leftField='system:time_start', rightField='system:time_start')\n",
    "            joined = join.apply(ic_to_map, agg_mod09, filter_time_eq)\n",
    "            \n",
    "            # function to calculate NIRv\n",
    "            def calc_nirv(joined_features):\n",
    "                ndvi_image = ee.Image(joined_features.get('primary'))\n",
    "                nir_image = ee.Image(joined_features.get('secondary'))\n",
    "                ndvi = ndvi_image.select('NDVI')\n",
    "                nir = nir_image.select('sur_refl_b02')\n",
    "                nirv_image = ndvi.multiply(nir).rename('NIRv')\n",
    "                return nirv_image.set('system:time_start', ndvi_image.get('system:time_start'))\n",
    "            \n",
    "            nirv_collection = ee.ImageCollection(joined.map(calc_nirv))\n",
    "            \n",
    "            output = ee.Algorithms.If(\n",
    "                condition=image_count.gt(0),\n",
    "                trueCase=get_values_from_image_collection(nirv_collection),\n",
    "                falseCase=ee.FeatureCollection([])\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            sys.exit(\"NIR image collection must provided for NIRv calculation.\")\n",
    "            \n",
    "    else:\n",
    "        # check how many images within the ic\n",
    "        image_count = ic_to_map.select(target).size()\n",
    "    \n",
    "        output = ee.Algorithms.If(\n",
    "            condition=image_count.gt(0),\n",
    "            trueCase=get_values_from_image_collection(ic_to_map),\n",
    "            falseCase=ee.FeatureCollection([])\n",
    "        )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Let's Get Things Done!\n",
    "\n",
    "It's time to start the main process!"
   ],
   "id": "bc9f7664d99fd461"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# First, get authenticate from Earth Engine\n",
    "ee.Authenticate()"
   ],
   "id": "8e6d0c51a2f084ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Next, link the Earth Engine API\n",
    "ee.Initialize(project='ee-charleshzijian')"
   ],
   "id": "a0a8f49fb401ba28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Then, mount Google Drive for shapefile\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "id": "bbe2e3491f1c479b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set the parameter for the process\n",
    "path_to_export = 'vi_ts'\n",
    "# Date range for image search\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2024-12-31'"
   ],
   "id": "5dcca381c4f95f0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now read the shapefile\n",
    "path_to_shapefile = r'/content/drive/MyDrive/Mangrove/China/ChinaMangrove2020'\n",
    "shapefile_to_map = gpd.read_file(path_to_shapefile + '/ChinaMangrove2020.shp').to_crs(\"epsg:4326\")\n",
    "source = 'drive'"
   ],
   "id": "f00bb83c2ce4ffa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Or load shapefile form Earth Engine\n",
    "mangrove_asset_id = 'projects/ee-charleshzijian/assets/China_Mangrove/Non-Protected'\n",
    "shapefile_to_map = ee.FeatureCollection(mangrove_asset_id)\n",
    "source = 'ee'"
   ],
   "id": "11a43326743003dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now load the MODIS image collection\n",
    "ic = ee.ImageCollection(\"MODIS/061/MOD13Q1\")    # for NDVI and EVI at 250 m\n",
    "ic_nir = ee.ImageCollection(\"MODIS/061/MOD09Q1\")    # for near-infrared surface reflectance at 250 m"
   ],
   "id": "55b4a7938a34b9e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Split and retrieve vegetation indices on every 400 features each time\n",
    "shp_idx = 0\n",
    "total_features = len(shapefile_to_map) if source == 'drive' else shapefile_to_map.size().getInfo()\n",
    "step_length = 400\n",
    "for i in range(shp_idx*step_length, total_features, step_length):\n",
    "    shp_idx += 1\n",
    "    # 1st -- get features ready\n",
    "    # -- slice the geo-dataframe\n",
    "    if source == 'drive':\n",
    "        gdf = shapefile_to_map.iloc[i:i+step_length]\n",
    "    else:\n",
    "        gdf = shapefile_to_map.toList(step_length, i)\n",
    "        \n",
    "    # # -- export the sliced geo-dataframe into a new shapefile [ONLY WHEN source == drive]\n",
    "    # export_slice = f\"ChinaMangrove_part{shp_idx}.shp\"\n",
    "    # gdf.to_file(f\"{path_to_export}/{export_slice}\",\n",
    "    #             driver='ESRI Shapefile')\n",
    "    \n",
    "    # 2nd -- get indices\n",
    "    for vi in ['NDVI', 'EVI', 'NIRv']:\n",
    "        print(f\">> Now on #{shp_idx} {vi}...\")\n",
    "        # convert the geo-dataframe to a list of dictionaries\n",
    "        if source == 'drive':\n",
    "            gdf_json = json.loads(gdf.to_json())[\"features\"]\n",
    "            # create a list of Earth Engine features\n",
    "            # ee_features = []\n",
    "            # for feature in features:\n",
    "            #     # extract geometry and properties\n",
    "            #     geometry = ee.Geometry.MultiLineString(feature['geometry']['coordinates'])\n",
    "            #     properties = feature['properties']\n",
    "            #     # create an Earth Engine feature\n",
    "            #     ee_feature = ee.Feature(geometry, properties)\n",
    "            #     # append to list\n",
    "            #     ee_features.append(ee_feature)\n",
    "            ee_features = [ee.Feature(ee.Geometry.MultiPolygon(feature['geometry']['coordinates']), feature['properties']) for feature in gdf_json]\n",
    "            # convert the list to a feature collection\n",
    "            features = ee.FeatureCollection(ee_features)\n",
    "            \n",
    "        else:\n",
    "            features = ee.FeatureCollection(gdf)\n",
    "            \n",
    "        # get mean vegetation index for each feature\n",
    "        if vi == 'NIRv':\n",
    "            result = features.map(lambda f: get_time_series(\n",
    "                roi=f, \n",
    "                image_collection=ic, \n",
    "                nir_collection=ic_nir,\n",
    "                date_start=start_date, \n",
    "                date_end=end_date, \n",
    "                target=vi\n",
    "            )).flatten()             \n",
    "        else:\n",
    "            result = features.map(lambda f: get_time_series(\n",
    "                roi=f, \n",
    "                image_collection=ic, \n",
    "                date_start=start_date, \n",
    "                date_end=end_date, \n",
    "                target=vi\n",
    "            )).flatten()        \n",
    "        \n",
    "        # export the result to a csv file\n",
    "        csv_name = f'Mean_{vi}_{shp_idx}'\n",
    "        task = ee.batch.Export.table.toDrive(\n",
    "            collection=result,\n",
    "            description=f'MODIS_{vi}_{shp_idx}',\n",
    "            folder=path_to_export,\n",
    "            fileNamePrefix=csv_name,\n",
    "            fileFormat='CSV'\n",
    "        )\n",
    "        task.start()\n",
    "        \n",
    "        print(f\"-- Task submitted at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}.\")\n",
    "        \n",
    "        # check if the task is still active every 30 seconds\n",
    "        while task.active():\n",
    "            time.sleep(30)\n",
    "            print(f\".. Task is running ({time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}).\")\n",
    "            \n",
    "        print(f\">> Task #{shp_idx} finished on {vi} calculation.\")\n",
    "        \n",
    "print(\">> ALL FEATURES PROCESSED.\")"
   ],
   "id": "4933f227d53d5f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "72e79446b5f852d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
